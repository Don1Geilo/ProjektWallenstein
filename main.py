# main.py
import os
import json
import pandas as pd
import gspread
from datetime import datetime, timezone

from stock_data import get_stock_data         # z.B. tÃ¤gliche Kursdaten
from reddit_scraper import get_reddit_posts   # reddit posts
from sentiment_analysis import analyze_sentiment
from google_sheets import open_google_sheet, create_chart

def main():
    # ğŸ”¥ 1) Google Sheet Ã¶ffnen
    spreadsheet = open_google_sheet()

    # ğŸ”¥ 2) Reddit Daten laden/scrapen
    reddit_data_file = "reddit_data.json"
    subreddits = ["WallStreetBets", "WallstreetbetsGer", "Mauerstrassenwetten"]
    all_posts = []

    if os.path.exists(reddit_data_file):
        with open(reddit_data_file, "r", encoding="utf-8") as f:
            all_posts = json.load(f)
        print(f"âœ… {len(all_posts)} gespeicherte Reddit-Posts geladen.")
    if len(all_posts) == 0:
        for sr in subreddits:
            posts = get_reddit_posts(sr, limit=50)
            all_posts.extend(posts)
        with open(reddit_data_file, "w", encoding="utf-8") as f:
            json.dump(all_posts, f, ensure_ascii=False, indent=4)
        print(f"âœ… Neue Reddit-Daten: {len(all_posts)} Posts gespeichert.")

    # ğŸ”¥ 3) Aktien definieren
    stocks = ["NVDA", "AAPL", "TSLA", "MSFT"]

    for stock_name in stocks:
        print(f"\nğŸ“Š Analysiere {stock_name}...")

        # Worksheet abrufen/erstellen
        try:
            worksheet = spreadsheet.worksheet(stock_name)
            print(f"ğŸ“‚ Arbeitsblatt '{stock_name}' gefunden, Daten werden aktualisiert.")
        except gspread.exceptions.WorksheetNotFound:
            worksheet = spreadsheet.add_worksheet(title=stock_name, rows="500", cols="20")
            print(f"ğŸ†• Neues Arbeitsblatt '{stock_name}' erstellt.")

        # ğŸ”¥ 4) Sentiment pro Tag
        sentiment_data = []
        for post in all_posts:
            if "date" in post and isinstance(post["date"], (int, float)):
                # date = Unix â†’ date()
                dt_day = datetime.fromtimestamp(post["date"], timezone.utc).date()
                val = analyze_sentiment(post["text"])  # JEDER Post
                sentiment_data.append({"Date": dt_day, "Sentiment": val})

        df_sentiment = pd.DataFrame(sentiment_data)
        if not df_sentiment.empty:
            df_sentiment["Date"] = pd.to_datetime(df_sentiment["Date"]).dt.date
            # Tagesaggregation
            df_sentiment = df_sentiment.groupby("Date").mean().reset_index()
        else:
            df_sentiment = pd.DataFrame(columns=["Date", "Sentiment"])

        # ğŸ”¥ 5) BÃ¶rsendaten (tÃ¤glich)
        stock_data = get_stock_data(stock_name)   # Muss Spalten [Date, Close, ...] liefern

        # ğŸ”¥ 6) Merge
        df_combined = pd.merge(stock_data, df_sentiment, on="Date", how="left")
        df_combined["Sentiment"] = df_combined["Sentiment"].fillna(0)

        # ğŸ”¥ 7) Positive/Negative Spalten
        df_combined["Sentiment_Pos"] = df_combined["Sentiment"].apply(lambda x: x if x > 0 else 0)
        df_combined["Sentiment_Neg"] = df_combined["Sentiment"].apply(lambda x: x if x < 0 else 0)

        # ğŸ”¥ 8) Achsen-Min/Max berechnen, damit Google Sheets NICHT bei 0 startet
        min_close = df_combined["Close"].min()
        max_close = df_combined["Close"].max()
        view_min = float(min_close * 0.95)  # 5% unter Minimum
        view_max = float(max_close * 1.05)  # 5% Ã¼ber Maximum

        # ğŸ”¥ 9) In Google Sheets hochladen (4 Spalten: Date, Close, Pos, Neg)
        df_combined["Date"] = df_combined["Date"].astype(str)
        df_upload = df_combined[["Date", "Close", "Sentiment_Pos", "Sentiment_Neg"]].fillna(0)

        data_sheet = [df_upload.columns.tolist()] + df_upload.values.tolist()
        worksheet.update(data_sheet)

        # ğŸ”¥ 10) Diagramm erstellen
        create_chart(worksheet, stock_name, view_min, view_max)

        print(f"âœ… {stock_name} erfolgreich gespeichert!")

    print("\nğŸš€ Alle Analysen abgeschlossen!\n")

if __name__ == "__main__":
    main()
